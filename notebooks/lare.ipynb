{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33525c72",
   "metadata": {},
   "source": [
    "## LaRE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6e0b118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41fc3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "from core import get_model\n",
    "# from torchsummary import summary\n",
    "import torch\n",
    "# from src.landmark_extraction import extract_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42659a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CLIP:RN50\"\n",
    "model = get_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d38de3aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msummary\u001b[49m(model.clip_model.visual, (\u001b[32m3\u001b[39m, \u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "summary(model.clip_model.visual, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50719a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CLIP:RN50\"\n",
    "model = get_model(model_name, type=\"wmap\", roi_pooling=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426eb9a1",
   "metadata": {},
   "source": [
    "### ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "937df5a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_rois' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load image and extract landmarks\u001b[39;00m\n\u001b[32m      2\u001b[39m image = \u001b[33m\"\u001b[39m\u001b[33m../assets/john.jpg\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m rois = \u001b[43mextract_rois\u001b[49m(image)\n\u001b[32m      4\u001b[39m boxes = [box \u001b[38;5;28;01mfor\u001b[39;00m box, _ \u001b[38;5;129;01min\u001b[39;00m rois]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Convert to tensor\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'extract_rois' is not defined"
     ]
    }
   ],
   "source": [
    "# Load image and extract landmarks\n",
    "image = \"../assets/john.jpg\"\n",
    "rois = extract_rois(image)\n",
    "boxes = [box for box, _ in rois]\n",
    "# Convert to tensor\n",
    "boxes_tensor = torch.tensor(boxes, dtype=torch.float32)  # shape (N_rois, 4)\n",
    "# Add batch indices (0 if only 1 image)\n",
    "batch_indices = torch.zeros((boxes_tensor.shape[0], 1), dtype=torch.float32)\n",
    "# Concatenate batch index\n",
    "boxes_tensor = torch.cat([batch_indices, boxes_tensor], dim=1)  # (N_rois, 5)\n",
    "print(boxes_tensor.shape)  # should be (N_rois, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa650120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "image = Image.open('../assets/john.jpg')\n",
    "# Resize to 224x224\n",
    "image = np.array(image.resize((224, 224)))\n",
    "image_tensor = torch.from_numpy(image).permute(2, 0, 1).float()  # C,H,W\n",
    "image_tensor /= 255.0\n",
    "image_tensor = image_tensor[np.newaxis, :]\n",
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3678d7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                   Model Summary                                                   </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Property             </span>┃<span style=\"font-weight: bold\"> Value                                                                                    </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Model                </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> CLIPClassifierWMap                                                                       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Parameters     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 104,453,515                                                                              </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Trainable Parameters </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 104,453,515                                                                              </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Trainable (Mi)       </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 99.61 Million                                                                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Summary              </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> =======================================================================================… </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Layer (type:depth-idx)                                            Param #                </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> =======================================================================================… </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> CLIP                                                              563,713                </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─ModifiedResNet: 1-1                                             38,316,896             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─Transformer: 1-2                                                37,828,608             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─Embedding: 1-3                                                  25,296,896             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─LayerNorm: 1-4                                                  1,024                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> =======================================================================================… </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Total params: 102,007,137                                                                </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Trainable params: 102,007,137                                                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Non-trainable params: 0                                                                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> =======================================================================================… </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Input Shape          </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> (1, 3, 224, 224)                                                                         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> CLIP.Visual          </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> =======================================================================================… </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Layer (type:depth-idx)                   Output Shape              Param #               </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> =======================================================================================… </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ModifiedResNet                           [1, 1024]                 --                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─Conv2d: 1-1                            [1, 32, 112, 112]         864                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─BatchNorm2d: 1-2                       [1, 32, 112, 112]         64                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─ReLU: 1-3                              [1, 32, 112, 112]         --                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─Conv2d: 1-4                            [1, 32, 112, 112]         9,216                 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─BatchNorm2d: 1-5                       [1, 32, 112, 112]         64                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─ReLU: 1-6                              [1, 32, 112, 112]         --                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─Conv2d: 1-7                            [1, 64, 112, 112]         18,432                </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─BatchNorm2d: 1-8                       [1, 64, 112, 112]         128                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─ReLU: 1-9                              [1, 64, 112, 112]         --                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─AvgPool2d: 1-10                        [1, 64, 56, 56]           --                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─Sequential: 1-11                       [1, 256, 56, 56]          215,808               </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─Sequential: 1-12                       [1, 512, 28, 28]          1,219,584             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─Sequential: 1-13                       [1, 1024, 14, 14]         7,098,368             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─Sequential: 1-14                       [1, 2048, 7, 7]           14,964,736            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ├─AttentionPool2d: 1-15                  [1, 1024]                 14,789,632            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> =======================================================================================… </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Total params: 38,316,896                                                                 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Trainable params: 38,316,896                                                             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Non-trainable params: 0                                                                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Total mult-adds (Units.GIGABYTES): 5.37                                                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> =======================================================================================… </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Input size (MB): 0.60                                                                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Forward/backward pass size (MB): 199.10                                                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Params size (MB): 94.11                                                                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Estimated Total Size (MB): 293.81                                                        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> =======================================================================================… </span>│\n",
       "└──────────────────────┴──────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                   Model Summary                                                   \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mProperty            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                                                                                   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mModel               \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mCLIPClassifierWMap                                                                      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTotal Parameters    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m104,453,515                                                                             \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTrainable Parameters\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m104,453,515                                                                             \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTrainable (Mi)      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m99.61 Million                                                                           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSummary             \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m=======================================================================================…\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mLayer (type:depth-idx)                                            Param #               \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m=======================================================================================…\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mCLIP                                                              563,713               \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─ModifiedResNet: 1-1                                             38,316,896            \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─Transformer: 1-2                                                37,828,608            \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─Embedding: 1-3                                                  25,296,896            \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─LayerNorm: 1-4                                                  1,024                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m=======================================================================================…\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mTotal params: 102,007,137                                                               \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mTrainable params: 102,007,137                                                           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mNon-trainable params: 0                                                                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m=======================================================================================…\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mInput Shape         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m(1, 3, 224, 224)                                                                        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCLIP.Visual         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m=======================================================================================…\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mLayer (type:depth-idx)                   Output Shape              Param #              \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m=======================================================================================…\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mModifiedResNet                           [1, 1024]                 --                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─Conv2d: 1-1                            [1, 32, 112, 112]         864                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─BatchNorm2d: 1-2                       [1, 32, 112, 112]         64                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─ReLU: 1-3                              [1, 32, 112, 112]         --                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─Conv2d: 1-4                            [1, 32, 112, 112]         9,216                \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─BatchNorm2d: 1-5                       [1, 32, 112, 112]         64                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─ReLU: 1-6                              [1, 32, 112, 112]         --                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─Conv2d: 1-7                            [1, 64, 112, 112]         18,432               \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─BatchNorm2d: 1-8                       [1, 64, 112, 112]         128                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─ReLU: 1-9                              [1, 64, 112, 112]         --                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─AvgPool2d: 1-10                        [1, 64, 56, 56]           --                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─Sequential: 1-11                       [1, 256, 56, 56]          215,808              \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─Sequential: 1-12                       [1, 512, 28, 28]          1,219,584            \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─Sequential: 1-13                       [1, 1024, 14, 14]         7,098,368            \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─Sequential: 1-14                       [1, 2048, 7, 7]           14,964,736           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m├─AttentionPool2d: 1-15                  [1, 1024]                 14,789,632           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m=======================================================================================…\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mTotal params: 38,316,896                                                                \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mTrainable params: 38,316,896                                                            \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mNon-trainable params: 0                                                                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mTotal mult-adds (Units.GIGABYTES): 5.37                                                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m=======================================================================================…\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mInput size (MB): 0.60                                                                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mForward/backward pass size (MB): 199.10                                                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mParams size (MB): 94.11                                                                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35mEstimated Total Size (MB): 293.81                                                       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m                      \u001b[0m│\u001b[35m \u001b[0m\u001b[35m=======================================================================================…\u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────────────┴──────────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "from torchinfo import summary\n",
    "\n",
    "import torch\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "def display_model_summary(model, input_shape=None, title=\"Model Summary\", device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Display model parameter summary using rich. Supports multiple inputs.\n",
    "\n",
    "    :param:\n",
    "        model: PyTorch model\n",
    "    :param:\n",
    "        input_shape: A single shape tuple or list/tuple e.g., (1, 3, 224, 224)\n",
    "    :param:\n",
    "        title: Optional table title\n",
    "    :param:\n",
    "        device: Device for dummy inputs\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    table = Table(title=title)\n",
    "    table.add_column(\"Property\", style=\"cyan\", no_wrap=True)\n",
    "    table.add_column(\"Value\", style=\"magenta\")\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    table.add_row(\"Model\", model.__class__.__name__)\n",
    "    table.add_row(\"Total Parameters\", f\"{total_params:,}\")\n",
    "    table.add_row(\"Trainable Parameters\", f\"{trainable_params:,}\")\n",
    "    table.add_row(\"Trainable (Mi)\", f\"{trainable_params / (1024 ** 2):.2f} Million\")\n",
    "    table.add_row(\"Summary\", f\"{summary(model.clip_model, depth=1)}\")\n",
    "\n",
    "    if input_shape is not None:\n",
    "        table.add_row(f\"Input Shape\", str(input_shape))\n",
    "        table.add_row(\"CLIP.Visual\", \n",
    "        f\"{summary(model.clip_model.visual, input_size=input_shape, depth=1)}\")\n",
    "\n",
    "    console = Console()\n",
    "    console.print(table)\n",
    "\n",
    "display_model_summary(model, input_shape=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72aeff20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'==========================================================================================\\nLayer (type:depth-idx)                   Output Shape              Param #\\n==========================================================================================\\nModifiedResNet                           [1, 1024]                 --\\n├─Conv2d: 1-1                            [1, 32, 112, 112]         864\\n├─BatchNorm2d: 1-2                       [1, 32, 112, 112]         64\\n├─ReLU: 1-3                              [1, 32, 112, 112]         --\\n├─Conv2d: 1-4                            [1, 32, 112, 112]         9,216\\n├─BatchNorm2d: 1-5                       [1, 32, 112, 112]         64\\n├─ReLU: 1-6                              [1, 32, 112, 112]         --\\n├─Conv2d: 1-7                            [1, 64, 112, 112]         18,432\\n├─BatchNorm2d: 1-8                       [1, 64, 112, 112]         128\\n├─ReLU: 1-9                              [1, 64, 112, 112]         --\\n├─AvgPool2d: 1-10                        [1, 64, 56, 56]           --\\n├─Sequential: 1-11                       [1, 256, 56, 56]          215,808\\n├─Sequential: 1-12                       [1, 512, 28, 28]          1,219,584\\n├─Sequential: 1-13                       [1, 1024, 14, 14]         7,098,368\\n├─Sequential: 1-14                       [1, 2048, 7, 7]           14,964,736\\n├─AttentionPool2d: 1-15                  [1, 1024]                 14,789,632\\n==========================================================================================\\nTotal params: 38,316,896\\nTrainable params: 38,316,896\\nNon-trainable params: 0\\nTotal mult-adds (Units.GIGABYTES): 5.37\\n==========================================================================================\\nInput size (MB): 0.60\\nForward/backward pass size (MB): 199.10\\nParams size (MB): 94.11\\nEstimated Total Size (MB): 293.81\\n=========================================================================================='"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = summary(model.clip_model.visual, input_size=(1, 3, 224, 224), depth=1)\n",
    "str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "760bb7c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/fomo/lib/python3.11/site-packages/torchinfo/torchinfo.py:295\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1538\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1538\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n",
      "\u001b[31mTypeError\u001b[39m: CLIP.forward() missing 1 required positional argument: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/fomo/lib/python3.11/site-packages/torchinfo/torchinfo.py:223\u001b[39m, in \u001b[36msummary\u001b[39m\u001b[34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[39m\n\u001b[32m    216\u001b[39m validate_user_params(\n\u001b[32m    217\u001b[39m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[32m    218\u001b[39m )\n\u001b[32m    220\u001b[39m x, correct_input_size = process_input(\n\u001b[32m    221\u001b[39m     input_data, input_size, batch_dim, device, dtypes\n\u001b[32m    222\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m summary_list = \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m formatting = FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[32m    227\u001b[39m results = ModelStatistics(\n\u001b[32m    228\u001b[39m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[32m    229\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/fomo/lib/python3.11/site-packages/torchinfo/torchinfo.py:304\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    303\u001b[39m     executed_layers = [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer.executed]\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    305\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "summary(model.clip_model, input_size=(3, 224, 224), depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccb80a6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m loss_map = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m32\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     logits = \u001b[43mmodel\u001b[49m(image_tensor, loss_map)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(logits.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "image_input = torch.randn(1, 3, 224, 224)\n",
    "loss_map = torch.randn(1, 4, 32, 32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(image_tensor, loss_map)\n",
    "    print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb00533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "loss_map_path = \"/home/scur0555/udit/lare/test/outputs/heygen/fake_000.pt\"\n",
    "loss_map = torch.load(loss_map_path)\n",
    "print(type(loss_map))  # Should be <class 'torch.Tensor'> if it was a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b8cd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 32, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(outs, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db56e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193b9ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[1.2722, 0.6045, 0.1884,  ..., 0.1580, 0.5751, 0.7202],\n",
       "          [0.5247, 0.1231, 0.0153,  ..., 0.9977, 0.2338, 0.3606],\n",
       "          [0.9416, 1.0371, 0.1474,  ..., 0.2346, 0.1005, 0.4632],\n",
       "          ...,\n",
       "          [0.0609, 0.4053, 0.1464,  ..., 0.1551, 0.2330, 0.2857],\n",
       "          [0.0782, 0.0202, 0.1628,  ..., 0.1930, 0.1445, 0.6617],\n",
       "          [0.1446, 0.0791, 0.1277,  ..., 0.0954, 0.1362, 0.5819]],\n",
       " \n",
       "         [[2.0497, 1.5650, 0.4817,  ..., 0.0799, 0.3167, 0.1323],\n",
       "          [0.3328, 0.5117, 0.0777,  ..., 0.1557, 0.3344, 0.3120],\n",
       "          [1.3182, 0.4221, 0.1938,  ..., 0.1400, 0.1776, 0.0101],\n",
       "          ...,\n",
       "          [0.0423, 0.0564, 0.1431,  ..., 0.8686, 0.2950, 0.7666],\n",
       "          [0.1798, 0.0861, 0.0021,  ..., 0.3287, 0.1534, 0.6862],\n",
       "          [0.0841, 0.1421, 0.4049,  ..., 0.1308, 0.2535, 0.2070]],\n",
       " \n",
       "         [[1.0831, 0.4674, 0.3141,  ..., 0.0589, 0.1330, 0.3242],\n",
       "          [1.2137, 0.8454, 0.3480,  ..., 0.2199, 0.3875, 1.4261],\n",
       "          [0.8819, 0.3374, 0.5654,  ..., 0.2056, 0.3830, 0.4163],\n",
       "          ...,\n",
       "          [0.4795, 0.0280, 0.0302,  ..., 0.4467, 0.5810, 0.5930],\n",
       "          [0.0836, 0.1374, 0.4609,  ..., 0.2312, 0.4311, 0.1080],\n",
       "          [0.0861, 0.0625, 0.3510,  ..., 0.1631, 0.1832, 0.0629]],\n",
       " \n",
       "         [[0.4976, 0.3088, 0.2078,  ..., 0.1034, 0.2628, 0.3800],\n",
       "          [0.2986, 0.3396, 0.1025,  ..., 0.1138, 0.2955, 0.2698],\n",
       "          [0.4495, 0.5106, 0.2056,  ..., 0.2087, 0.1082, 0.0395],\n",
       "          ...,\n",
       "          [0.0284, 0.0071, 0.0349,  ..., 0.4515, 0.1744, 1.2013],\n",
       "          [0.0376, 0.0654, 0.2014,  ..., 0.2908, 0.8109, 0.1485],\n",
       "          [0.1679, 0.0553, 0.3263,  ..., 0.1004, 0.0847, 0.1114]]]),\n",
       " tensor([[[1.2722, 0.6045, 0.1884,  ..., 0.1580, 0.5751, 0.7202],\n",
       "          [0.5247, 0.1231, 0.0153,  ..., 0.9977, 0.2338, 0.3606],\n",
       "          [0.9416, 1.0371, 0.1474,  ..., 0.2346, 0.1005, 0.4632],\n",
       "          ...,\n",
       "          [0.0609, 0.4053, 0.1464,  ..., 0.1551, 0.2330, 0.2857],\n",
       "          [0.0782, 0.0202, 0.1628,  ..., 0.1930, 0.1445, 0.6617],\n",
       "          [0.1446, 0.0791, 0.1277,  ..., 0.0954, 0.1362, 0.5819]],\n",
       " \n",
       "         [[2.0497, 1.5650, 0.4817,  ..., 0.0799, 0.3167, 0.1323],\n",
       "          [0.3328, 0.5117, 0.0777,  ..., 0.1557, 0.3344, 0.3120],\n",
       "          [1.3182, 0.4221, 0.1938,  ..., 0.1400, 0.1776, 0.0101],\n",
       "          ...,\n",
       "          [0.0423, 0.0564, 0.1431,  ..., 0.8686, 0.2950, 0.7666],\n",
       "          [0.1798, 0.0861, 0.0021,  ..., 0.3287, 0.1534, 0.6862],\n",
       "          [0.0841, 0.1421, 0.4049,  ..., 0.1308, 0.2535, 0.2070]],\n",
       " \n",
       "         [[1.0831, 0.4674, 0.3141,  ..., 0.0589, 0.1330, 0.3242],\n",
       "          [1.2137, 0.8454, 0.3480,  ..., 0.2199, 0.3875, 1.4261],\n",
       "          [0.8819, 0.3374, 0.5654,  ..., 0.2056, 0.3830, 0.4163],\n",
       "          ...,\n",
       "          [0.4795, 0.0280, 0.0302,  ..., 0.4467, 0.5810, 0.5930],\n",
       "          [0.0836, 0.1374, 0.4609,  ..., 0.2312, 0.4311, 0.1080],\n",
       "          [0.0861, 0.0625, 0.3510,  ..., 0.1631, 0.1832, 0.0629]],\n",
       " \n",
       "         [[0.4976, 0.3088, 0.2078,  ..., 0.1034, 0.2628, 0.3800],\n",
       "          [0.2986, 0.3396, 0.1025,  ..., 0.1138, 0.2955, 0.2698],\n",
       "          [0.4495, 0.5106, 0.2056,  ..., 0.2087, 0.1082, 0.0395],\n",
       "          ...,\n",
       "          [0.0284, 0.0071, 0.0349,  ..., 0.4515, 0.1744, 1.2013],\n",
       "          [0.0376, 0.0654, 0.2014,  ..., 0.2908, 0.8109, 0.1485],\n",
       "          [0.1679, 0.0553, 0.3263,  ..., 0.1004, 0.0847, 0.1114]]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs = [loss_map, loss_map]\n",
    "outs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fomo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

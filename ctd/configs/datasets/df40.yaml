mode: train
dataset_root: /scratch-shared/scur0555/datasets/clipping_the_deception/
dataset_manifest: /scratch-shared/scur0555/datasets/clipping_the_deception/manifest.json
log_dir: ~/fomo_logdir

class_to_label: { fake: 1, real: 0 }

# model setting
pretrained_path: ~/fomo_logdir/model.pth
model_name: clip # model name
backbone_name: vit # backbone name

backbone_config:
  mode: original
  num_classes: 2
  inc: 3
  dropout: false

train_batch_size: 32
test_batch_size: 32
workers: 8
frame_num: { train: 8, test: 8 } # number of frames to use per video in training and testing
resolution: 224 # resolution of output image to network
clip_size: 16 # number of frames in each clip

# data augmentation
use_data_augmentation: true # Add this flag to enable/disable data augmentation
data_aug:
  flip_prob: 0.5
  rotate_prob: 0.5
  rotate_limit: [-10, 10]
  blur_prob: 0.5
  blur_limit: [3, 7]
  brightness_prob: 0.5
  brightness_limit: [-0.1, 0.1]
  contrast_limit: [-0.1, 0.1]
  quality_lower: 40
  quality_upper: 100

# mean and std for normalization
mean: [0.5, 0.5, 0.5]
std: [0.5, 0.5, 0.5]
